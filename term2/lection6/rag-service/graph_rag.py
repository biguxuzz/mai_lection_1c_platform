import os
import asyncio
import json
from typing import List, Dict, Optional, Any
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker
from sqlalchemy.pool import NullPool
from openai import AsyncOpenAI
import logging

logger = logging.getLogger(__name__)


class GraphRAG:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥—Ä–∞—Ñ–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π RAG
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç PostgreSQL + pgvector –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    –∏ Apache AGE –¥–ª—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Å–≤—è–∑–µ–π
    """
    
    def __init__(self):
        self.db_url = os.getenv("DATABASE_URL")
        self.lmstudio_url = os.getenv("LMSTUDIO_BASE_URL", "http://host.docker.internal:1234/v1")
        self.embedding_model_name = os.getenv("EMBEDDING_MODEL", "text-embedding-nomic-embed-text-v1.5")
        self.llm_model_name = os.getenv("LLM_MODEL", "llama-3.2-3b-instruct")
        self.embedding_dimensions = int(os.getenv("EMBEDDING_DIMENSIONS", "768"))
        
        self.engine = None
        self.Session = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LMStudio
        self.client = AsyncOpenAI(
            base_url=self.lmstudio_url,
            api_key="lm-studio"  # LMStudio –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π API –∫–ª—é—á
        )
        
        logger.info(f"GraphRAG –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        logger.info(f"  - LMStudio URL: {self.lmstudio_url}")
        logger.info(f"  - Embedding –º–æ–¥–µ–ª—å: {self.embedding_model_name}")
        logger.info(f"  - LLM –º–æ–¥–µ–ª—å: {self.llm_model_name}")
        logger.info(f"  - –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {self.embedding_dimensions}")
    
    async def initialize(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–æ–≤"""
        try:
            # –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î
            logger.info("üîÑ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL...")
            self.engine = create_engine(
                self.db_url,
                poolclass=NullPool,
                echo=False
            )
            self.Session = sessionmaker(bind=self.engine)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î
            if await self.check_db_connection():
                logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ PostgreSQL —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            else:
                raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ PostgreSQL")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio
            logger.info("üîÑ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio...")
            await self._check_lmstudio_connection()
            
            logger.info("‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è GraphRAG –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            raise
    
    async def _check_lmstudio_connection(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
        try:
            models = await self.client.models.list()
            available_models = [m.id for m in models.data]
            logger.info(f"‚úÖ LMStudio –ø–æ–¥–∫–ª—é—á–µ–Ω. –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏: {available_models}")
            
            if not available_models:
                logger.warning("‚ö†Ô∏è –í LMStudio –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏!")
                logger.warning("   –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –º–æ–¥–µ–ª–∏ –≤ LMStudio –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º")
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio: {e}")
            logger.warning("   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ:")
            logger.warning("   1. LMStudio –∑–∞–ø—É—â–µ–Ω –Ω–∞ http://127.0.0.1:1234")
            logger.warning("   2. –í –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö LMStudio –≤–∫–ª—é—á–µ–Ω—ã CORS –∏ Network Access")
            logger.warning("   3. –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å")
    
    async def _get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ LMStudio"""
        try:
            response = await self.client.embeddings.create(
                model=self.embedding_model_name,
                input=text
            )
            embedding = response.data[0].embedding
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏
            if len(embedding) != self.embedding_dimensions:
                logger.warning(
                    f"‚ö†Ô∏è –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ ({len(embedding)}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –æ–∂–∏–¥–∞–µ–º—ã–º ({self.embedding_dimensions})"
                )
            
            return embedding
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥: {str(e)}")
    
    async def ingest_document(self, content: str, metadata: Optional[Dict] = None) -> int:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        
        Args:
            content: –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            metadata: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            
        Returns:
            ID –¥–æ–±–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        """
        session = self.Session()
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ —á–µ—Ä–µ–∑ LMStudio
            logger.info("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞...")
            embedding = await self._get_embedding(content)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            if metadata is None:
                metadata = {}
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            logger.info("üîÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ –ë–î...")
            result = session.execute(
                text(f"""
                    INSERT INTO documents (content, embedding, metadata)
                    VALUES (:content, :embedding::vector({self.embedding_dimensions}), :metadata::jsonb)
                    RETURNING id
                """),
                {
                    "content": content,
                    "embedding": str(embedding),
                    "metadata": json.dumps(metadata)
                }
            )
            doc_id = result.fetchone()[0]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ
            logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ...")
            await self._create_graph_nodes(session, doc_id, content, metadata)
            
            session.commit()
            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –¥–æ–±–∞–≤–ª–µ–Ω —Å ID: {doc_id}")
            return doc_id
            
        except Exception as e:
            session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            raise
        finally:
            session.close()
    
    async def _create_graph_nodes(self, session, doc_id: int, content: str, metadata: Dict):
        """–°–æ–∑–¥–∞–Ω–∏–µ —É–∑–ª–æ–≤ –∏ —Å–≤—è–∑–µ–π –≤ –≥—Ä–∞—Ñ–µ Apache AGE"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑–æ–≤–æ–≥–æ —É–∑–ª–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            preview = content[:200].replace("'", "''")  # –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–≤—ã—á–µ–∫
            source = metadata.get('source', 'unknown').replace("'", "''")
            
            session.execute(
                text("""
                    SELECT * FROM cypher('knowledge_graph', $$
                        CREATE (d:Document {
                            doc_id: $doc_id,
                            preview: $preview,
                            source: $source,
                            length: $length
                        })
                        RETURN d
                    $$) as (node agtype);
                """),
                {
                    "doc_id": doc_id,
                    "preview": preview,
                    "source": source,
                    "length": len(content)
                }
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≤—è–∑–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å —É–∑–ª–æ–º
            session.execute(
                text("""
                    INSERT INTO document_nodes (document_id, node_id, node_type, properties)
                    VALUES (:doc_id, :node_id, 'Document', :props)
                """),
                {
                    "doc_id": doc_id,
                    "node_id": doc_id,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º doc_id –∫–∞–∫ node_id
                    "props": json.dumps({"source": metadata.get('source', 'unknown')})
                }
            )
            
            logger.info(f"‚úÖ –ì—Ä–∞—Ñ–æ–≤—ã–π —É–∑–µ–ª —Å–æ–∑–¥–∞–Ω –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc_id}")
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ —É–∑–ª–∞: {e}")
            # –ù–µ –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å, –µ—Å–ª–∏ –≥—Ä–∞—Ñ –Ω–µ —Å–æ–∑–¥–∞–ª—Å—è
    
    async def query(
        self,
        question: str,
        top_k: int = 5,
        use_graph: bool = True,
        similarity_threshold: float = 0.0
    ) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π
        
        Args:
            question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            use_graph: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –≥—Ä–∞—Ñ–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            similarity_threshold: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –æ—Ç–≤–µ—Ç–æ–º, –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏ –∏ –≥—Ä–∞—Ñ–æ–≤—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        """
        session = self.Session()
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –≤–æ–ø—Ä–æ—Å–∞
            logger.info("üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –∑–∞–ø—Ä–æ—Å–∞...")
            question_embedding = await self._get_embedding(question)
            
            # –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            logger.info("üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            result = session.execute(
                text(f"""
                    SELECT 
                        id,
                        content,
                        metadata,
                        1 - (embedding <=> :embedding::vector({self.embedding_dimensions})) as similarity
                    FROM documents
                    WHERE embedding IS NOT NULL
                      AND (1 - (embedding <=> :embedding::vector({self.embedding_dimensions}))) >= :threshold
                    ORDER BY embedding <=> :embedding::vector({self.embedding_dimensions})
                    LIMIT :limit
                """),
                {
                    "embedding": str(question_embedding),
                    "limit": top_k,
                    "threshold": similarity_threshold
                }
            )
            
            documents = result.fetchall()
            logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            if not documents:
                logger.warning("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—è—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º –ø–æ–∏—Å–∫–∞")
                return {
                    "answer": "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.",
                    "sources": [],
                    "graph_context": None
                }
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            graph_context = None
            if use_graph and documents:
                logger.info("üï∏Ô∏è –ü–æ–ª—É—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞...")
                graph_context = await self._get_graph_context(session, documents)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM
            context = self._build_context(documents, graph_context)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM...")
            answer = await self._generate_answer(question, context)
            
            return {
                "answer": answer,
                "sources": [
                    {
                        "id": doc[0],
                        "content": doc[1][:300],  # –ü–µ—Ä–≤—ã–µ 300 —Å–∏–º–≤–æ–ª–æ–≤
                        "similarity": round(float(doc[3]), 4),
                        "metadata": doc[2]
                    }
                    for doc in documents
                ],
                "graph_context": graph_context
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            raise
        finally:
            session.close()
    
    async def _get_graph_context(self, session, documents) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        try:
            doc_ids = [doc[0] for doc in documents]
            
            # Cypher –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤
            result = session.execute(
                text("""
                    SELECT * FROM cypher('knowledge_graph', $$
                        MATCH (d:Document)
                        WHERE d.doc_id IN $doc_ids
                        OPTIONAL MATCH (d)-[r]-(related)
                        RETURN d, type(r) as rel_type, related
                        LIMIT 20
                    $$) as (doc agtype, rel_type agtype, related agtype);
                """),
                {"doc_ids": doc_ids}
            )
            
            graph_data = result.fetchall()
            
            if not graph_data:
                return None
            
            return {
                "nodes_found": len(graph_data),
                "has_relationships": any(row[1] is not None for row in graph_data),
                "sample_nodes": len(graph_data)
            }
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {e}")
            return None
    
    def _build_context(self, documents, graph_context: Optional[Dict]) -> str:
        """–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è LLM –∏–∑ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        context_parts = ["–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:\n"]
        
        for idx, doc in enumerate(documents, 1):
            similarity = float(doc[3])
            content = doc[1]
            metadata = doc[2] if doc[2] else {}
            
            source_info = f" (–ò—Å—Ç–æ—á–Ω–∏–∫: {metadata.get('source', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')})" if metadata else ""
            context_parts.append(
                f"\n[–î–æ–∫—É–º–µ–Ω—Ç {idx} | –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {similarity:.2%}]{source_info}:\n{content}\n"
            )
        
        if graph_context and graph_context.get('nodes_found', 0) > 0:
            context_parts.append(
                f"\n[–ì—Ä–∞—Ñ–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç]: –ù–∞–π–¥–µ–Ω–æ {graph_context['nodes_found']} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —É–∑–ª–æ–≤ –≤ –≥—Ä–∞—Ñ–µ –∑–Ω–∞–Ω–∏–π."
            )
        
        return "\n".join(context_parts)
    
    async def _generate_answer(self, question: str, context: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é LLM —á–µ—Ä–µ–∑ LMStudio"""
        try:
            response = await self.client.chat.completions.create(
                model=self.llm_model_name,
                messages=[
                    {
                        "role": "system",
                        "content": """–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
–ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º.
–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —á–µ—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É."""
                    },
                    {
                        "role": "user",
                        "content": f"{context}\n\n–í–æ–ø—Ä–æ—Å: {question}\n\n–û—Ç–≤–µ—Ç:"
                    }
                ],
                temperature=0.7,
                max_tokens=800,
                top_p=0.9
            )
            
            answer = response.choices[0].message.content.strip()
            logger.info("‚úÖ –û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
            return answer
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return f"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}"
    
    async def delete_document(self, doc_id: int):
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        session = self.Session()
        try:
            result = session.execute(
                text("DELETE FROM documents WHERE id = :id"),
                {"id": doc_id}
            )
            
            if result.rowcount == 0:
                raise Exception(f"–î–æ–∫—É–º–µ–Ω—Ç —Å ID {doc_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
            session.commit()
            logger.info(f"‚úÖ –î–æ–∫—É–º–µ–Ω—Ç {doc_id} —É–¥–∞–ª–µ–Ω")
            
        except Exception as e:
            session.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            raise
        finally:
            session.close()
    
    async def get_documents_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º"""
        session = self.Session()
        try:
            result = session.execute(text("SELECT * FROM documents_stats"))
            row = result.fetchone()
            
            if row:
                return {
                    "total_documents": row[0],
                    "documents_with_embeddings": row[1],
                    "unique_sources": row[2],
                    "first_document_date": str(row[3]) if row[3] else None,
                    "last_document_date": str(row[4]) if row[4] else None
                }
            else:
                return {
                    "total_documents": 0,
                    "documents_with_embeddings": 0,
                    "unique_sources": 0,
                    "first_document_date": None,
                    "last_document_date": None
                }
        finally:
            session.close()
    
    async def check_db_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            session = self.Session()
            session.execute(text("SELECT 1"))
            session.close()
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            return False
    
    async def check_llm_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio"""
        try:
            await self.client.models.list()
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LMStudio: {e}")
            return False

